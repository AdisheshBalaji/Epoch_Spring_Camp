{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b799a31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a50b1bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [150, 7.0, 1, 'Apple'],\n",
    "    [120, 6.5, 0, 'Banana'],\n",
    "    [180, 7.5, 2, 'Orange'],\n",
    "    [155, 7.2, 1, 'Apple'],\n",
    "    [110, 6.0, 0, 'Banana'],\n",
    "    [190, 7.8, 2, 'Orange'],\n",
    "    [145, 7.1, 1, 'Apple'],\n",
    "    [115, 6.3, 0, 'Banana']\n",
    "]\n",
    "\n",
    "labels = {\"Apple\": 0, \"Banana\": 1, \"Orange\": 2}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "633fd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, n_features):\n",
    "    data = np.array(data)\n",
    "    X = data[:, 0:n_features]\n",
    "    X = X.astype(float)\n",
    "    y = data[:, n_features]\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "45f1d904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Apple', 'Banana', 'Orange', 'Apple', 'Banana', 'Orange', 'Apple',\n",
       "       'Banana'], dtype='<U32')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 3\n",
    "X_train, y_train = data_split(data, n_features)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a0a54a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing train_test_split similar to the function in sklearn\n",
    "def train_test_split(X, y, test_size):\n",
    "    rows_X = X.shape[0]\n",
    "    rows_y = y.shape[0]\n",
    "    \n",
    "    #Since test_size lies between 0 and 1, we determine a split index to split the dataset into test/train data\n",
    "    split_index = int(rows_X*(1 - test_size))\n",
    "    \n",
    "    X_train = X[:split_index, :]\n",
    "    X_test = X[split_index:, :]\n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[:split_index]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ab9aee",
   "metadata": {},
   "source": [
    "We define accuracy as\n",
    "$$\n",
    "    \\text{accuracy} = 1 - \\frac{\\sum_{i=1}^{n} \\mathbf{1}(y_{\\text{pred}}[i] \\neq y_{\\text{true}}[i])}{n}\n",
    "$$\n",
    "\n",
    "Where **1** represents the indicator function that $y_{pred} = y_{true}$ and $n$ the length of $y_{pred}$. Intuitively, 1 means perfect accuracy and 0 means 0 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "fb57e4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    anomaly = 0\n",
    "    for val in range(len(y_pred)):\n",
    "        if y_pred[val] != y_true[val]:\n",
    "            anomaly += 1\n",
    "    accuracy = 1 - anomaly/len(y_pred)\n",
    "    return accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d717f2",
   "metadata": {},
   "source": [
    "We define the $p^{th}$ norm to compute distance in an $n$-dimensional space\n",
    "\n",
    "$$\n",
    "     L_p(x_1, x_2) = \\|x_1 - x_2\\|_p = \\left( \\sum_{i = 1}^{n} \\left| x_{1i} - x_{2i} \\right|^p \\right)^{\\frac{1}{p}}\n",
    "$$\n",
    "\n",
    "When $p = 1$, the distance is termed as **Manhattan Distance** </br>\n",
    "When $p = 2$, the distance is termed as **Euclidean Distance** </br>\n",
    "When $p > 2$, it is generalized as **Minkowski Distance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "89006ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(a, b):\n",
    "    return np.linalg.norm(a - b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fce5ac17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(a, b, p):\n",
    "    return np.sum(np.abs(a - b)**p)**(1 / p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "08c7a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan_distance(a, b):\n",
    "    return np.sum(np.abs(a - b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d33d7",
   "metadata": {},
   "source": [
    "We normalize each element in X_train using **min-max normalization** .ie\n",
    "$$\n",
    "    x_{new} = \\frac{x - x_{min}}{x_{max} - x_{min}}\n",
    "$$\n",
    "Where $x_{min}$ and $x_{max}$ are the minimum and maximum elements of the corresponding column respectively. </br>\n",
    "This ensures that all the points in X_train are normalized between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c5340c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    \n",
    "    #modifying the columns in place\n",
    "    for val in range(len(arr)):\n",
    "        arr[val] = (arr[val] - min_val)/(max_val - min_val)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c4599b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(X_train):\n",
    "    for cols in range(X_train.shape[1]):\n",
    "        normalize(X_train[:, cols])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "5f25cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "8a514109",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    #the parameter p defines which distance metric we are using\n",
    "    def __init__(self, k = 3, p = None):\n",
    "        self.k = k\n",
    "        self.p = p\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "       \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    \n",
    "    def distance(self, p):\n",
    "        if p == 1:\n",
    "            return manhattan_distance\n",
    "        elif p == 2:\n",
    "            return euclidean_distance\n",
    "        else:\n",
    "            return lambda x1, x2: minkowski_distance(x1, x2, p=self.p)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        predicted_classes = []\n",
    "        for x in range(X_test.shape[0]):\n",
    "            pred = self.predict_one(X_test[x])\n",
    "            predicted_classes.append(pred)\n",
    "            \n",
    "        return predicted_classes\n",
    "            \n",
    "        \n",
    "    def predict_one(self, x):\n",
    "        #storing the best distances from each point in X_train with the new point\n",
    "        distances = []\n",
    "        for rows in range(self.X_train.shape[0]):\n",
    "            #calculating the euclidean distance between each row of X with the new point\n",
    "            distance_fn = self.distance(self.p)\n",
    "            distance = distance_fn(self.X_train[rows, :], x)\n",
    "            distances.append(distance)\n",
    "\n",
    "        distances = np.array(distances)\n",
    "\n",
    "        #returning the closest k neighbours to new point\n",
    "        idx_min_k = np.argsort(distances)[:self.k]\n",
    "\n",
    "        #calculating the mode of the classes of the k closest neighbours\n",
    "        classes_min_k = self.y_train[idx_min_k]\n",
    "        predicted_class = Counter(classes_min_k).most_common(1)[0][0]\n",
    "        return predicted_class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "cfaa17c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#We first evaluate the test data using k = 3 and euclidean distance\n",
    "test_data = np.array([\n",
    "    [118, 6.2, 0],  # Expected: Banana\n",
    "    [160, 7.3, 1],  # Expected: Apple\n",
    "    [185, 7.7, 2]   # Expected: Orange\n",
    "])\n",
    "\n",
    "normalization(test_data)\n",
    "\n",
    "y_true = [\"Banana\", \"Apple\", \"Orange\"]\n",
    "\n",
    "knn = KNN(k=3, p = 2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(test_data)\n",
    "\n",
    "print(accuracy(y_pred, y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d99f8c",
   "metadata": {},
   "source": [
    "We use KNN with varying $k$ and varying distance metric to predict the classes for each point on the test dataset, and correspondingly, print the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "41daafe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluation():\n",
    "    for k in range(1, 6):\n",
    "        for p in range(1, 4):\n",
    "            knn = KNN(k = k, p = p)\n",
    "            knn.fit(X_train, y_train)\n",
    "            y_pred = knn.predict(test_data)\n",
    "            accuracy_score = accuracy(y_pred, y_true)\n",
    "            print(f\"Predictions for k = {k}, p = {p}: {y_pred}, accuracy = {accuracy_score : .2f}\")\n",
    "        print(\"\\n\\n\")\n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "0a91f3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for k = 1, p = 1: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 1, p = 2: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 1, p = 3: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "\n",
      "\n",
      "\n",
      "Predictions for k = 2, p = 1: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 2, p = 2: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 2, p = 3: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "\n",
      "\n",
      "\n",
      "Predictions for k = 3, p = 1: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 3, p = 2: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 3, p = 3: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "\n",
      "\n",
      "\n",
      "Predictions for k = 4, p = 1: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 4, p = 2: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "Predictions for k = 4, p = 3: ['Banana', 'Apple', 'Orange'], accuracy =  1.00\n",
      "\n",
      "\n",
      "\n",
      "Predictions for k = 5, p = 1: ['Banana', 'Apple', 'Apple'], accuracy =  0.67\n",
      "Predictions for k = 5, p = 2: ['Banana', 'Apple', 'Apple'], accuracy =  0.67\n",
      "Predictions for k = 5, p = 3: ['Banana', 'Apple', 'Apple'], accuracy =  0.67\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2d5fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
