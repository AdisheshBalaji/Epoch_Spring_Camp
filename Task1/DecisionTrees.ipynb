{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "fcd0a23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "922cfe11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['12.0', '1.5', '1', 'Wine'],\n",
       "       ['5.0', '2.0', '0', 'Beer'],\n",
       "       ['40.0', '0.0', '1', 'Whiskey'],\n",
       "       ['13.5', '1.2', '1', 'Wine'],\n",
       "       ['4.5', '1.8', '0', 'Beer'],\n",
       "       ['38.0', '0.1', '1', 'Whiskey'],\n",
       "       ['11.5', '1.7', '1', 'Wine'],\n",
       "       ['5.5', '2.3', '0', 'Beer']], dtype='<U32')"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [\n",
    "    [12.0, 1.5, 1, 'Wine'],\n",
    "    [5.0, 2.0, 0, 'Beer'],\n",
    "    [40.0, 0.0, 1, 'Whiskey'],\n",
    "    [13.5, 1.2, 1, 'Wine'],\n",
    "    [4.5, 1.8, 0, 'Beer'],\n",
    "    [38.0, 0.1, 1, 'Whiskey'],\n",
    "    [11.5, 1.7, 1, 'Wine'],\n",
    "    [5.5, 2.3, 0, 'Beer']\n",
    "]\n",
    "data = np.array(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "f1a79d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, n_features):\n",
    "    X = data[:, 0:n_features]\n",
    "    X = X.astype(float)\n",
    "    y = data[:, n_features]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "c9bb3f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3\n",
    "X, y = data_split(data, n_features)\n",
    "labels = [\"Wine\", \"Beer\", \"Whiskey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e71bad5",
   "metadata": {},
   "source": [
    "### Gini Impurity\n",
    "  Gini Impurity is one of the commonly used criterion to evalutate the goodness of a split, the lower the gini impurity, the better the split. Mathematically, it is defined as\n",
    "  \n",
    "  $$\n",
    "    G(S) = 1 - \\sum_{i=1}^n p_i^{2}  \n",
    "  $$\n",
    "  \n",
    "  Where $p_i$ is the proportion of elements in the $i^{th}$ class.\n",
    "  $$\n",
    "      0 \\leq G(S) \\leq 1\n",
    "  $$\n",
    "  We get 0 for a pure class, consisting of only one value and 1 for maximum impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "98dccf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65625"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini_impurity(y):\n",
    "    #creating a frequency list for the labels\n",
    "    labels_list = [0, 0, 0]\n",
    "    for i in range(len(y)):\n",
    "        for j in range(len(labels)):\n",
    "            if y[i] == labels[j]:\n",
    "                labels_list[j] += 1\n",
    "    gini = 1\n",
    "    #calculating gini value\n",
    "    for i in range(len(labels_list)):\n",
    "        if(sum(labels_list) == 0):\n",
    "            return 1\n",
    "        gini -= (labels_list[i]/sum(labels_list))**2\n",
    "    return gini\n",
    "\n",
    "gini_impurity(y)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c088299",
   "metadata": {},
   "source": [
    "We must return the threshold with the least **weighted gini-impurity** which is calculated for a column as \n",
    "$$\n",
    "    G_{split} = \\frac{N_L}{N} G_L + \\frac{N_R}{N}G_R\n",
    "$$\n",
    "Where $G_L$ and $G_R$ are the gini impurities for the left and right sides of the threshold respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "2f5a6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def weighted_gini(left_y, right_y):\n",
    "        total = len(left_y) + len(right_y)\n",
    "        if total == 0:\n",
    "            return 0\n",
    "        gini_left = gini_impurity(left_y)\n",
    "        gini_right = gini_impurity(right_y)\n",
    "        return (len(left_y) * gini_left + len(right_y) * gini_right) / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b06a2b",
   "metadata": {},
   "source": [
    "### Calculation Of Entropy \n",
    "Entropy is alternative function used to compute like gini used in decision trees. It is similarly used to find the best split, it is calculated as\n",
    "\n",
    "$$\n",
    "    H(S) = -\\sum_{i = 1}^{c}p_i \\log_2 p_i\n",
    "$$\n",
    "\n",
    "$p_i$ simply represents the proportion of elements in the $i^{th}$ class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "a3f4fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    labels = [\"Wine\", \"Beer\", \"Whiskey\"]\n",
    "    labels_list = [0, 0, 0]\n",
    "    for i in range(len(y)):\n",
    "        for j in range(len(labels)):\n",
    "            if y[i] == labels[j]:\n",
    "                labels_list[j] += 1  # Increment count for the corresponding label\n",
    "\n",
    "    entropy_value = 0\n",
    "    for i in range(len(labels_list)):\n",
    "        p = labels_list[i] / len(y)  # Probability of each label\n",
    "        if p > 0:  # To prevent log(0), which is undefined\n",
    "            entropy_value -= p * np.log2(p)\n",
    "    \n",
    "    return entropy_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78efca",
   "metadata": {},
   "source": [
    "### Information Gain\n",
    "\n",
    "**Information Gain** uses entropy to measure the effectiveness of a split in a dataset. If we split a dataset \\( S \\) using a feature \\( A \\), the Information Gain is calculated as:\n",
    "\n",
    "$$\n",
    "IG(S, A) = H(S) - \\sum_{v \\in \\text{values}(A)} \\frac{|S_v|}{|S|} H(S_v)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $H(S)$ is the entropy of the original dataset $ S$  \n",
    "- $\\text{values}(A)$ are the unique values of feature $A$  \n",
    "- $S_v$ is the subset of $S$ where $A = v$  \n",
    "\n",
    "The feature and threshold with the **highest Information Gain** is selected for the split.\n",
    "\n",
    "It can also be written as:\n",
    "\n",
    "$$\n",
    "\\text{Information Gain} = \\text{Entropy before split} - \\text{Entropy after split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "0b05d957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(X_column, y, threshold):\n",
    "    left_mask = X_column <= threshold\n",
    "    right_mask = X_column > threshold\n",
    "\n",
    "    y_left = y[left_mask]\n",
    "    y_right = y[right_mask]\n",
    "\n",
    "    entropy_before = entropy(y)\n",
    "    entropy_after = (len(y_left) / len(y)) * entropy(y_left) + (len(y_right) / len(y)) * entropy(y_right)\n",
    "\n",
    "    gain = entropy_before - entropy_after\n",
    "    return gain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e0df3",
   "metadata": {},
   "source": [
    "###  Method: Node Initialization\n",
    "\n",
    "Initializes a node in the decision tree.\n",
    "\n",
    "**Parameters:**\n",
    "\n",
    "- `feature_index`: Index of the feature to split on\n",
    "- `threshold`: Threshold value for the split\n",
    "- `left`: Left child node\n",
    "- `right`: Right child node\n",
    "- `value`: Predicted class if the node is a leaf\n",
    "- `depth`: Depth of the node in the tree\n",
    "- `gini`: Gini impurity of the node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "748bcaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None, depth=None, gini=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.depth = depth\n",
    "        self.gini = gini\n",
    "\n",
    "    @staticmethod\n",
    "    def split(X, y, feature_index, threshold):\n",
    "        left_mask = X[:, feature_index] <= threshold\n",
    "        right_mask = X[:, feature_index] > threshold\n",
    "\n",
    "        left_X = X[left_mask]\n",
    "        left_y = y[left_mask]\n",
    "        right_X = X[right_mask]\n",
    "        right_y = y[right_mask]\n",
    "\n",
    "        return left_X, right_X, left_y, right_y\n",
    "\n",
    "    @staticmethod\n",
    "    def build_tree(X, y, depth, param):\n",
    "        max_depth = 10\n",
    "\n",
    "        # Base case\n",
    "        if depth >= max_depth or len(np.unique(y)) == 1:\n",
    "            leaf_value = Counter(y).most_common(1)[0][0]\n",
    "            return Node(value=leaf_value, depth=depth, gini=0)\n",
    "\n",
    "\n",
    "        # Try finding best split\n",
    "        best_split = best_split_fn(X, y, param) \n",
    "        if best_split is None:\n",
    "            leaf_value = Counter(y).most_common(1)[0][0]\n",
    "            return Node(value=leaf_value, depth=depth, gini=0)\n",
    "\n",
    "        left_X, right_X, left_y, right_y, best_feature, best_threshold = best_split\n",
    "\n",
    "        left_node = Node.build_tree(left_X, left_y, depth + 1, param)\n",
    "        right_node = Node.build_tree(right_X, right_y, depth + 1, param)\n",
    "\n",
    "        return Node(\n",
    "            feature_index=best_feature,\n",
    "            threshold=best_threshold,\n",
    "            left=left_node,\n",
    "            right=right_node,\n",
    "            gini=None,  # or calculate if needed\n",
    "            depth=depth\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5aa058",
   "metadata": {},
   "source": [
    "For obtaining the candidate thresholds at each feature, we first sort the array and the find the midpoints of each successive 2 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "afe554e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_thresholds(feature_arr):\n",
    "        feature_arr = np.sort(np.unique(feature_arr))\n",
    "        thresholds = []\n",
    "        for i in range(len(feature_arr) - 1):\n",
    "            thresholds.append((feature_arr[i] + feature_arr[i+1])/2)\n",
    "        return thresholds\n",
    "    \n",
    "    Node.get_thresholds = staticmethod(get_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681ad065",
   "metadata": {},
   "source": [
    "Function to determine the best split at each feature index based on the **information gain** or **gini-impurity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "id": "54e23082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split_fn(X, y, param):\n",
    "    if param == \"entropy\":\n",
    "        #initializing best_gain to 0, since we must maximize information gain\n",
    "        best_gain = 0.0\n",
    "        best_threshold = None\n",
    "        best_feature = None\n",
    "        best_split = None\n",
    "        \n",
    "        #loop through each feature in the feature matrix\n",
    "        for feature_index in range(X.shape[1]):\n",
    "            thresholds = Node.get_thresholds(X[:, feature_index])\n",
    "            \n",
    "            #evaluate information gain at each possible threshold, and returning the optimal threshold value\n",
    "            for threshold in thresholds:\n",
    "                left_X, right_X, left_y, right_y = Node.split(X, y, feature_index, threshold)\n",
    "                if len(left_y) == 0 or len(right_y) == 0:\n",
    "                    continue\n",
    "                \n",
    "                gain = information_gain(X[:, feature_index], y, threshold)\n",
    "                if gain >= best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "                    best_split = (left_X, right_X, left_y, right_y, best_feature, best_threshold)\n",
    "        \n",
    "        #returning best feature and threshold\n",
    "        return best_split\n",
    "    \n",
    "    #similarly for the gini part, just copied the entropy function\n",
    "    elif param == \"gini\":\n",
    "            best_gini = 1.01\n",
    "            best_threshold = None\n",
    "            best_feature = None\n",
    "            best_split = None\n",
    "            for feature_index in range(X.shape[1]):\n",
    "                thresholds = Node.get_thresholds(X[:, feature_index])\n",
    "                for threshold in thresholds:\n",
    "                    left_X, right_X, left_y, right_y = Node.split(X, y, feature_index, threshold)\n",
    "                    if len(left_y) == 0 or len(right_y) == 0:\n",
    "                        continue\n",
    "                    gini = weighted_gini(left_y, right_y)\n",
    "                    if gini <= best_gini:\n",
    "                        best_gini = gini\n",
    "                        best_feature = feature_index\n",
    "                        best_threshold = threshold\n",
    "                        best_split = (left_X, right_X, left_y, right_y, best_feature, best_threshold)\n",
    "            return best_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "24c08790",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict_one(self, x):\n",
    "        # If there are no children\n",
    "        if self.value is not None:\n",
    "            return self.value\n",
    "\n",
    "        # if value is less than threshold, we go to left child\n",
    "        if x[self.feature_index] <= self.threshold:\n",
    "            return self.left.predict_one(x)\n",
    "        #if value is greater than threshold, we go to right child\n",
    "        else:\n",
    "            return self.right.predict_one(x)\n",
    "        \n",
    "Node.predict_one = predict_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "3656a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(self, X):\n",
    "        return np.array([self.predict_one(x) for x in X])\n",
    "Node.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "54247669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict labels for test data using parameter as gini\n",
    "def evaluation_gini():\n",
    "    tree = Node.build_tree(X, y, depth = 0, param = \"gini\")\n",
    "    test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "    ])\n",
    "    print(tree.predict(test_data))\n",
    "\n",
    "#function to plot the tree\n",
    "def plot_tree_gini():\n",
    "    tree = Node.build_tree(X, y,depth = 0, param = \"gini\")\n",
    "    test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "    ])\n",
    "    feature_names = [\"Alcohol_Content\", \"Sugar\", \"Color\"]\n",
    "    print_tree(tree, feature_names, max_depth = np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "ac3c7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict labels for test data using parameter as information gain\n",
    "def evaluation_entropy():\n",
    "    tree = Node.build_tree(X, y, depth = 0, param = \"entropy\")\n",
    "    test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "    ])\n",
    "    print(tree.predict(test_data))\n",
    "\n",
    "#function to plot the tree\n",
    "def plot_tree_entropy():\n",
    "    tree = Node.build_tree(X, y, depth = 0, param = \"entropy\")\n",
    "    test_data = np.array([\n",
    "    [6.0, 2.1, 0],   # Expected: Beer\n",
    "    [39.0, 0.05, 1], # Expected: Whiskey\n",
    "    [13.0, 1.3, 1]   # Expected: Wine\n",
    "    ])\n",
    "    feature_names = [\"Alcohol_Content\", \"Sugar\", \"Color\"]\n",
    "    print_tree(tree, feature_names, max_depth = np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "1b76b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Whiskey' 'Wine']\n"
     ]
    }
   ],
   "source": [
    "evaluation_gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "04052f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if Color <= 0.50:\n",
      "    Predict -> Beer\n",
      "else:\n",
      "    if Sugar <= 0.65:\n",
      "        Predict -> Whiskey\n",
      "    else:\n",
      "        Predict -> Wine\n"
     ]
    }
   ],
   "source": [
    "plot_tree_gini()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "97d35de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beer' 'Whiskey' 'Wine']\n"
     ]
    }
   ],
   "source": [
    "evaluation_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "e2b43283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if Color <= 0.50:\n",
      "    Predict -> Beer\n",
      "else:\n",
      "    if Sugar <= 0.65:\n",
      "        Predict -> Whiskey\n",
      "    else:\n",
      "        Predict -> Wine\n"
     ]
    }
   ],
   "source": [
    "plot_tree_entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab65d645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
